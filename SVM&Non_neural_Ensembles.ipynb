{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMy_bsQ4_oe5"
      },
      "source": [
        "Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5BndT_L3gpw"
      },
      "outputs": [],
      "source": [
        "#---- Wall Breakers----#\n",
        "# Sunny Kaushik-- IMT2021007---#\n",
        "# Shrey Salaria-- IMT2021087---#\n",
        "# Akash Perla-- IMT2021530---#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S89wtU-lbAW2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "import sklearn\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7LVf-_z4PD9"
      },
      "outputs": [],
      "source": [
        "train_df=pd.read_csv(\"augmented_train.csv\")\n",
        "test_df=pd.read_csv(\"test.csv\")\n",
        "# train_df[\"Journey_Time\"] = train_df[\"Journey_Time\"].apply(lambda x: max(min(x, 80), 12))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 1 (**for running SVM part only**)\n",
        "#Pre-processing and fitting\n",
        "train_data = train_data.dropna()\n",
        "\n",
        "# Replace rows with mean values in the test data\n",
        "test_data.fillna(test_data.mean(), inplace=True)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming you have imported the LabelEncoder from scikit-learn\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_cols = ['Bus_ID', 'Bus_Operator', 'Departure_Bus_Stop', 'Arrival_Bus_Stop', 'Day']\n",
        "\n",
        "# Fit and transform on the training data\n",
        "for col in categorical_cols:\n",
        "    label_encoder.fit(train_data[col])\n",
        "    train_data[col] = label_encoder.transform(train_data[col])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_cols = ['Bus_ID', 'Bus_Operator', 'Departure_Bus_Stop', 'Arrival_Bus_Stop', 'Day']\n",
        "# Transform the test data using the same encoder\n",
        "for col in categorical_cols:\n",
        "     test_data[col] = label_encoder.transform(test_data[col])\n",
        "\n",
        "X_train = train_data.drop(['Index', 'Target', 'DepartureTime'], axis=1)  # Remove non-numeric columns\n",
        "y_train = train_data['Target']\n",
        "X_test = test_data.drop(['Index', 'DepartureTime'], axis=1)  # Remove non-numeric columns\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "val_predictions1 = svm_classifier.predict(X_val)\n",
        "\n",
        "svm_classifier_poly = SVC(kernel='poly', degree=3, C=1.0)\n",
        "svm_classifier_poly.fit(X_train_scaled, y_train)\n",
        "val_predictions2 = svm_classifier_poly.predict(X_val)\n",
        "\n",
        "svm_classifier_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')  # Adjust the gamma parameter as needed\n",
        "svm_classifier_rbf.fit(X_train_scaled, y_train)\n",
        "val_predictions3 = svm_classifier_rbf.predict(X_val)\n",
        "\n",
        "# Calculate and print the accuracy on the validation set for all models\n",
        "val_accuracy1 = accuracy_score(y_val, val_predictions1)\n",
        "val_accuracy2 = accuracy_score(y_val, val_predictions2)\n",
        "val_accuracy3 = accuracy_score(y_val, val_predictions3)\n",
        "print(f'Validation Accuracy for linear kernel: {val_accuracy1}')\n",
        "print(f'Validation Accuracy for polynomial kernel: {val_accuracy2}')\n",
        "print(f'Validation Accuracy for rbf kernel: {val_accuracy3}')\n",
        "\n",
        "# **SVM part ends**\n",
        "# Run this independently from part 2 and 3"
      ],
      "metadata": {
        "id": "LMKONidjFFeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPrvtQKGaPKG"
      },
      "outputs": [],
      "source": [
        "train_df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vwyhCvH6Mp7"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "train_df.fillna(train_df.mode().iloc[0], inplace=True)\n",
        "test_df.fillna(test_df.mode().iloc[0], inplace=True)\n",
        "# train_df.fillna(-999, inplace=True)\n",
        "# test_df.fillna(-999, inplace=True)\n",
        "# train_df['categorical_column'].fillna(train_df['categorical_column'].mode().iloc[0], inplace=True)\n",
        "# test_df['categorical_column'].fillna(test_df['categorical_column'].mode().iloc[0], inplace=True)\n",
        "# train_df.interpolate(method='linear', inplace=True)\n",
        "# test_df.interpolate(method='linear', inplace=True)\n",
        "# categorical_columns = ['Bus_Operator', 'Departure_Bus_Stop','Arrival_Bus_Stop']  # Replace with actual column names\n",
        "# # Replace missing values in categorical columns based on probabilities\n",
        "# for col in categorical_columns:\n",
        "#     prob = train_df[col].value_counts() / len(train_df[col])\n",
        "#     train_df[col].fillna(pd.Series(np.random.choice(prob.index, p=prob.values, size=len(train_df))), inplace=True)\n",
        "#     test_df[col].fillna(pd.Series(np.random.choice(prob.index, p=prob.values, size=len(test_df))), inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dCo-nJS7Kkw"
      },
      "outputs": [],
      "source": [
        "X=train_df.iloc[:,1:8]\n",
        "Y=train_df.iloc[:,-1]\n",
        "#X = X.drop('Day', axis=1)\n",
        "#X = X.drop('Journey_Time', axis=1)\n",
        "#X = X.drop('Bus_ID', axis=1)\n",
        "# X = X.drop('Bus_Operator', axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4l7uTmJ7lNM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.99, random_state=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsVZGfrc2aqh"
      },
      "outputs": [],
      "source": [
        "X_test_df=test_df.iloc[:,1:8]\n",
        "#X_test_df = X_test_df.drop('Day', axis=1)\n",
        "#X_test_df = X_test_df.drop('Bus_ID', axis=1)\n",
        "# X_test_df = X_test_df.drop('Bus_Operator', axis=1)\n",
        "#X_test_df = X_test_df.drop('Journey_Time', axis=1)\n",
        "# scaler = StandardScaler()\n",
        "# X_test_df = scaler.fit_transform(X_test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SyuBFgPZR0b",
        "outputId": "7d6c9ff2-a69c-4828-87ef-c264bfaa13bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting category-encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.14.0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders) (0.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category-encoders) (2023.3.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category-encoders) (3.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category-encoders) (23.2)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install category-encoders\n",
        "\n",
        "import category_encoders as ce\n",
        "encoder = ce.TargetEncoder(cols=['Bus_ID','Bus_Operator', 'Departure_Bus_Stop', 'Arrival_Bus_Stop','Day'])\n",
        "X_train = encoder.fit_transform(X_train, Y_train)\n",
        "X_test = encoder.transform(X_test)\n",
        "X_test_df=encoder.transform(X_test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkScp8lw61v1"
      },
      "outputs": [],
      "source": [
        "# # Create an IterativeImputer instance\n",
        "imputer = IterativeImputer(max_iter=10000, random_state=32)\n",
        "\n",
        "# Fit the imputer on the dataset and transform the data\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test_df = imputer.fit_transform(X_test_df)\n",
        "\n",
        "imputer = IterativeImputer(max_iter=10000, random_state=32)\n",
        "\n",
        "# Fit the imputer on the dataset and transform the data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxejTM2-QND3"
      },
      "outputs": [],
      "source": [
        "#defining models to use in ensemble learning\n",
        "models={}\n",
        "models_ensemble={}\n",
        "import xgboost\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "models['LR']=LogisticRegression()\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "models['DT']=DecisionTreeClassifier()\n",
        "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor,RandomForestClassifier\n",
        "models['RF']=RandomForestClassifier()\n",
        "from xgboost import XGBClassifier\n",
        "models['XG']=XGBClassifier()\n",
        "from sklearn.svm import LinearSVC\n",
        "models['svm']=LinearSVC()\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "models['ext']=ExtraTreesClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lszst1HeTDLD",
        "outputId": "ef7c7d1c-9c85-483d-9fc3-adb81bcbd8d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Bagging and Boosting\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "svm_model = SVC(kernel='rbf', C=1.0, probability=True)  # Define SVM with chosen hyperparameters\n",
        "tree=XGBClassifier(\n",
        "    n_estimators=280,\n",
        "    max_depth=9,\n",
        "    learning_rate=0.1,\n",
        "    min_child_weight=1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0,\n",
        "    reg_alpha=0.01,\n",
        "    reg_lambda=1,\n",
        "    objective='binary:logistic'\n",
        ")\n",
        "models_ensemble['Bagging']=BaggingClassifier(base_estimator=svm_model, n_estimators=20,random_state=23)\n",
        "models_ensemble['Bagging'].fit(X_train,Y_train)\n",
        "y_pred = models_ensemble['Bagging'].predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred))\n",
        "print(f1_score(Y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cof-lWMm2TWJ"
      },
      "outputs": [],
      "source": [
        "#code to print the final submission file\n",
        "label=test_df.iloc[:,0]\n",
        "y_pred_test = models_ensemble['Bagging'].predict(X_test_df)\n",
        "y_pred_test = y_pred_test.reshape(len(y_pred_test),1)\n",
        "y_pred_test=np.array(y_pred_test)\n",
        "label = label.values.reshape(-1,1)\n",
        "label=np.array(label)\n",
        "result=np.concatenate((label,y_pred_test),axis=1)\n",
        "result_df=pd.DataFrame(result,columns=['Index','Target'])\n",
        "result_df.to_csv('r2f7.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BI47574JVdkb"
      },
      "outputs": [],
      "source": [
        "#Voting Classifier\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "clf1=RandomForestClassifier()\n",
        "clf2=XGBClassifier()\n",
        "clf3=DecisionTreeClassifier()\n",
        "clf4=LinearSVC()\n",
        "clf5=ExtraTreesClassifier()\n",
        "model1=VotingClassifier(estimators=[('RFC',clf1),('xgb',clf2)],voting='soft')\n",
        "model1.fit(X_train,Y_train)\n",
        "y_pred = model1.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred))\n",
        "print(f1_score(Y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TimOnsJpYMS-"
      },
      "outputs": [],
      "source": [
        "#code to print the final submission file\n",
        "label=test_df.iloc[:,0]\n",
        "y_pred_test = model1.predict(X_test_df)\n",
        "y_pred_test = y_pred_test.reshape(len(y_pred_test),1)\n",
        "y_pred_test=np.array(y_pred_test)\n",
        "label = label.values.reshape(-1,1)\n",
        "label=np.array(label)\n",
        "result=np.concatenate((label,y_pred_test),axis=1)\n",
        "result_df=pd.DataFrame(result,columns=['Index','Target'])\n",
        "result_df.to_csv('r2f6.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking Classifier\n",
        "\n",
        "from sklearn. model_selection import train_test_split\n",
        "from sklearn. metrics import accuracy_score\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "models_ensemble[ 'Stacked'] = StackingClassifier(estimators=[('m1', models['DT']),('m2', models['RF'])], final_estimator=models['XG'])\n",
        "models_ensemble['Stacked'].fit(X_train,Y_train)\n",
        "y_pred = models_ensemble['Stacked'].predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred))\n",
        "print(f1_score(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "-axYSCeArk_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}